# ---- 1-1 Libraries for Path and Logging ----
import os
import sys
import typer
from tqdm import tqdm
from pathlib import Path
from loguru import logger
# è·å–å½“å‰ Jupyter Notebook æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
current_dir = Path.cwd()

# è·å–å½“å‰ç›®å½•çš„ä¸Šçº§ç›®å½•çš„ä¸Šçº§ç›®å½•
ADDR_ROOT = current_dir.parent.parent

# è®¾ç½®ä»£ç ç›®å½•è·¯å¾„
ADDR_CODE = ADDR_ROOT / "codes"

sys.path.append(str(ADDR_ROOT))
sys.path.append(str(ADDR_CODE))

logger.success(f"ADDR_ROOT set to: {ADDR_ROOT}")
logger.success(f"ADDR_CODE  set to: {ADDR_CODE}")

# ---- 1-2 Libraries for Configuration and Modules ----
from codes.function.Log import log
import codes.function.Train as Train
import codes.function.Loss as lossfunction
from codes.config.config_DDPM import EvalConfig
from codes.config.config_DDPM import ModelConfig
from codes.function.Dataset import ImageDataset, DataModule
# ---- 1-3 PyTorch ----
import torch
import torch.cuda
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader,random_split, ConcatDataset
# ---- 1-4 Others ----
import scipy
import importlib
import numpy as np
import seaborn as sns
from datetime import datetime
import matplotlib.pyplot as plt

import deeplay as dl
# ---- 1-5 eval ----
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
from torchmetrics.image import MultiScaleStructuralSimilarityIndexMeasure as MS_SSIM
from torchmetrics.image import StructuralSimilarityIndexMeasure as SSIM
from torchmetrics.image import PeakSignalNoiseRatio as PSNR
from torchmetrics.regression import MeanAbsoluteError as MAE


import torch
print(torch.__version__) # Note the double underscores before and after 'version'
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)


# ---- 0. é…ç½®ä¸è®¾å¤‡ ----
eval_cfg = EvalConfig()
model_cfg = ModelConfig()

# ç”¨ä¼ å‚è¦†ç›–é»˜è®¤
exp_name = eval_cfg.exp_name
# data_dir = eval_cfg.data_dir
# data_dir = Path("/root/autodl-fs")
data_dir = Path("D:/Research$Study/LHAI/LHAI-codes/data/Evaluation")
data_name = 'halo_test_width_v2.npy'
model_name_diffusion = eval_cfg.model_name_diffusion
model_name_unet = eval_cfg.model_name_unet
model_dir =  eval_cfg.model_dir
seed = eval_cfg.seed
frac = eval_cfg.frac
epochs = eval_cfg.epochs
batch_size = eval_cfg.batch_size
lr_max = eval_cfg.lr_max
lr_min = eval_cfg.lr_min
datarange = eval_cfg.datarange
LoB = eval_cfg.LoB
dataname = eval_cfg.dataname

data_path = data_dir / data_name
model_path = model_dir / f"{model_name_diffusion}.py"
model_weight_name = "Last_DDPM_EXP01_400epo_32bth_xingwei.pth"
# model_weight_dir = Path("/root/LHAI/saves/MODEL/DDPM")
model_weight_dir = Path("D:/Research$Study/LHAI/LHAI-codes/saves/MODEL/DDPM")
model_weight_path = model_weight_dir / model_weight_name

torch.manual_seed(seed)
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)

logger.success("========= 2-1 å‚æ•°åŠ è½½å®Œæˆ =========")


# ==== 2-2 Data: trainloader & testloader ====
dm = DataModule(
data_path=data_path,
batch_size=batch_size,
frac=frac,
inverse=False,
shuffle_train=False,
shuffle_test=False,
num_workers=0,
pin_memory=False,
drop_last=False,
)

trainloader, testloader = dm.build()

for batch_idx, (blurry_img, original_img) in enumerate(testloader):
    if batch_idx == 0:
        blurry_img_shape = blurry_img.shape  # ç¤ºä¾‹ï¼š(32, 1, 64, 64)
        original_img_shape = original_img.shape
        blurry_img_numpy = blurry_img[1].squeeze().detach().cpu().numpy()
        blurry_img_min = blurry_img_numpy.min()
        blurry_img_max = blurry_img_numpy.max()
        blurry_img_sample = blurry_img_numpy
        break

logger.info(f"""
====================== æ•°æ®å‚æ•° ======================
Output of data from Batch 1

- blurry image     : {blurry_img_shape} [æ‰¹æ¬¡, é€šé“æ•°, é«˜åº¦, å®½åº¦]
- clear image      : {original_img_shape} [æ‰¹æ¬¡, é€šé“æ•°, é«˜åº¦, å®½åº¦]
- datarange        : æœ€å°å€¼ = {blurry_img_min:.6f}, æœ€å¤§å€¼ = {blurry_img_max:.6f}
- 1st image output :

{np.array2string(blurry_img_sample, precision=4, suppress_small=True, threshold=64)}
===============================================================
""")

logger.success("========= 2-2 æ•°æ®åŠ è½½å®Œæˆ =========")


# ==== 2-3 Initialize the model ====
# DIFFUSION
model_params = model_cfg.model_params
params_diffusion = model_params[model_name_diffusion]
params_unet = model_params[model_name_unet]

sys.path.append(str(model_dir))
module_diffusion = importlib.import_module(model_name_diffusion)
DIFFUSION = getattr(module_diffusion, model_name_diffusion)

diffusion = DIFFUSION(**params_diffusion)

# Unet
model_params = model_cfg.model_params
params_unet = model_params[model_name_unet]
sys.path.append(str(model_dir))
module_unet = importlib.import_module(model_name_unet)
UNET = getattr(module_unet, model_name_unet)

unet = UNET(**params_unet).to(device)
unet.build()
unet.to(device)

# åŠ è½½æƒé‡
unet.load_state_dict(torch.load(model_weight_path, map_location=device))

# loss
trainingloss = lossfunction.msejsloss

logger.success(f"========= 2-3 æ¨¡å‹ã€æ¨¡å‹å‚æ•°ä¸lossåŠ è½½å®Œæˆ =========")


# ==== 2-4 Evaluation ====

# save path
dataname = data_name.split("_")[0]
save_dir_eval = ADDR_ROOT / "saves" / "EVAL" / model_name_diffusion
if not os.path.exists(save_dir_eval):
    os.makedirs(save_dir_eval)

# logger output
format_model_params = Train.format_model_params
torch.set_printoptions(precision=10)
train_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No CUDA device"
loss_name = trainingloss.__name__
model_params_str_diffusion = format_model_params(model_params[model_name_diffusion])
model_params_str_unet = format_model_params(model_params[model_name_unet])
filetmp = np.load(data_path, allow_pickle=True)
filelen = int(filetmp.shape[0])
del filetmp
train_msg = f"""
====================== è¯„ä¼°å‚æ•° ======================
ğŸ”§ é…ç½®ä¿¡æ¯æ¦‚è§ˆï¼š
- traintime               : {train_time}
- exp_name                : {exp_name}
- model_name              : {model_name_diffusion} + {model_name_unet}
- data_name               : {data_name}ï¼ˆ{dataname}ï¼‰
- model_path              : {model_path}
- data_path               : {data_path}
- seed                    : {seed}
- frac                    : è®­ç»ƒé›† {frac*100:.1f}% / æµ‹è¯•é›† {100-frac*100:.1f}%
- datalength              : {filelen}
- epochs                  : {epochs}
- batch_size              : {batch_size}
- datarange               : {datarange}
- learnrate               : æœ€å° = {lr_min:.1e}, æœ€å¤§ = {lr_max:.1e}
- lossname                : {loss_name}
- device                  : {device}({gpu_name})
- model_params_diffusion  : 

{model_params_str_diffusion}
- model_params_unet       :

{model_params_str_unet}
==============================================================
"""
logger.info(train_msg)


# ---- 2-4 evaluation 2: lineprofiles and resmap----
def interp2d(x1,x2,y1,y2,arr):
    x = np.arange(arr.shape[0])
    y = np.arange(arr.shape[0])
    xx,yy = np.meshgrid(x,y)
    interpolate = scipy.interpolate.RegularGridInterpolator((x,y),arr)
    y_t = np.linspace(x1,x2,101)
    x_t = np.linspace(y1,y2,101)
    z_t = interpolate((x_t,y_t))
    return z_t

# è·å–æµ‹è¯•é›†ä¸­çš„ç¬¬ä¸€æ‰¹å›¾åƒ
test_input_images, test_target_images = next(iter(testloader))
test_input_images = test_input_images.to(device)
test_target_images = test_target_images.to(device)

n_images = 10 # æ˜¾ç¤ºå‰nå¼ å›¾åƒ

# æ¨ç†ï¼ˆç”Ÿæˆé«˜åˆ†è¾¨å›¾åƒåºåˆ—ï¼‰
with torch.no_grad():
    generated_images = diffusion.reverse_diffusion(
        model=unet,
        n_images=n_images,
        n_channels=1,
        input_image=test_input_images[:n_images],
        save_time_steps=None
    )

# è½¬ç½®ç»´åº¦ï¼Œä» (T, B, C, H, W) â†’ (B, T, C, H, W)
generated_images = generated_images.swapaxes(0, 1)

showlist = [0,1,2,3,4,5]# ä½ å¯ä»¥æ”¹è¿™ä¸ªï¼Œå±•ç¤ºå“ªå‡ å¼ å›¾
num_images_to_show = len(showlist)
xys = np.zeros(num_images_to_show).tolist()
for i in range(num_images_to_show):
    xys[i] = [0,0,0,0]
xys[0] = [10, 50, 37, 37]
xys[1] = [10, 40, 20, 5]
xys[2] = [40, 50, 20, 10]
xys[3] = [20, 40, 40, 23]
xys[4] = [20, 50, 50, 40]
xys[5] = [20, 60, 60, 20]

# æå–å›¾åƒï¼šä½åˆ†è¾¨å›¾ / ç”Ÿæˆå›¾ / åŸå§‹å›¾
img_LR = test_input_images.cpu()
img_HR = test_target_images.cpu()

fig, axes = plt.subplots(num_images_to_show, 6, figsize=(18, 3 * num_images_to_show))

for i in range(num_images_to_show):
    count = showlist[i]
    x1, x2, y1, y2 = xys[i]
    color = 'white'

    # æå–å›¾åƒ
    blurry_img_numpy = img_LR[count].squeeze().numpy()
    original_img_numpy = img_HR[count].squeeze().numpy()

    image_diff_trajectory = generated_images[:, count]
    sr_img_numpy = image_diff_trajectory[-1].cpu()
    sr_img_numpy = sr_img_numpy.squeeze().numpy()

    # å½’ä¸€åŒ–ï¼ˆå¯é€‰ï¼‰
    blurry_img_numpy = blurry_img_numpy / blurry_img_numpy.sum()
    sr_img_numpy = sr_img_numpy / sr_img_numpy.sum()
    original_img_numpy = original_img_numpy / original_img_numpy.sum()

    # Blurry å›¾åƒ
    axes[i, 0].imshow(blurry_img_numpy, cmap='viridis')
    axes[i, 0].set_title('Blurry Image')
    axes[i, 0].plot([x1, x2], [y1, y2], linestyle='--', color=color, linewidth=2)
    axins = inset_axes(axes[i, 0], width="20%", height="20%", loc=4)
    axins.axis('off')
    axins.patch.set_alpha(0)
    axins.plot(interp2d(x1, x2, y1, y2, blurry_img_numpy), color=color)

    # SR å›¾åƒ
    axes[i, 1].imshow(sr_img_numpy, cmap='viridis')
    axes[i, 1].set_title('SR Image')
    axes[i, 1].plot([x1, x2], [y1, y2], linestyle='--', color=color, linewidth=2)
    axins = inset_axes(axes[i, 1], width="20%", height="20%", loc=4)
    axins.axis('off')
    axins.patch.set_alpha(0)
    axins.plot(interp2d(x1, x2, y1, y2, sr_img_numpy), color=color)

    # åŸå§‹ HR å›¾åƒ
    axes[i, 2].imshow(original_img_numpy, cmap='viridis')
    axes[i, 2].set_title('Original Image')
    axes[i, 2].plot([x1, x2], [y1, y2], linestyle='--', color=color, linewidth=2)
    axins = inset_axes(axes[i, 2], width="20%", height="20%", loc=4)
    axins.axis('off')
    axins.patch.set_alpha(0)
    axins.plot(interp2d(x1, x2, y1, y2, original_img_numpy), color=color)

    # æ®‹å·®å›¾
    res_blur = blurry_img_numpy - original_img_numpy
    res_sr = sr_img_numpy - original_img_numpy
    vmin = min(res_blur.min(), res_sr.min())
    vmax = max(res_blur.max(), res_sr.max())

    im3 = axes[i, 3].imshow(res_blur, vmin=vmin, vmax=vmax, cmap='viridis')
    axes[i, 3].set_title('Res Blur')
    fig.colorbar(im3, ax=axes[i, 3], shrink=0.5)

    im4 = axes[i, 4].imshow(res_sr, vmin=vmin, vmax=vmax, cmap='viridis')
    axes[i, 4].set_title('Res SR')
    fig.colorbar(im4, ax=axes[i, 4], shrink=0.5)

    # æ›²çº¿å›¾
    axes[i, 5].plot(interp2d(x1, x2, y1, y2, blurry_img_numpy), color='red', label='Blurry')
    axes[i, 5].plot(interp2d(x1, x2, y1, y2, sr_img_numpy), color='blue', label='SR')
    axes[i, 5].plot(interp2d(x1, x2, y1, y2, original_img_numpy), color='black', label='Original')
    axes[i, 5].set_title('Line Profiles')
    axes[i, 5].legend()

plt.tight_layout()
savepath = f'{ADDR_ROOT}/saves'
savefigname = f"Eval_distribution_{model_weight_name}"
savefig2_path = f'{save_dir_eval}/{savefigname}.png'
plt.savefig(savefig2_path, dpi=300)
logger.success(f"Evaluation 1: Loss figure saved at {savefig2_path}")
logger.success("========= 2-4-2 lineprofiles and resmap è¯„ä¼°å®Œæˆ =========")


# ---- 2-4 evaluation 4: NRMSE,MAE,MS-SSIM,SSIM,PSNR ----
ms_ssim_metric = MS_SSIM(
    data_range=2.0, kernel_size=7, betas=(0.0448, 0.2856, 0.3001)
).to(device)
ssim_metric = SSIM(data_range=2.0).to(device)
psnr_metric = PSNR(data_range=2.0).to(device)
mae_metric = MAE().to(device)

# ä½ å·²æœ‰çš„æµ‹è¯•è¾“å…¥å›¾åƒ
all_inputs = []
all_targets = []
for inputs, targets in testloader:
    all_inputs.append(inputs)
    all_targets.append(targets)
test_input_images  = torch.cat(all_inputs, dim=0).to(device)
test_target_images = torch.cat(all_targets, dim=0).to(device)

n_images = 2000

# æ¨ç†ç”Ÿæˆé«˜åˆ†è¾¨å›¾åƒåºåˆ—
with torch.no_grad():
    generated_images = diffusion.reverse_diffusion(
        model=unet,
        n_images=n_images,
        n_channels=1,
        input_image=test_input_images[:n_images],
        save_time_steps=None
    )

# è½¬ç½®ç»´åº¦ (T, B, C, H, W) â†’ (B, T, C, H, W)
generated_images = generated_images.unsqueeze(0)

# å­˜å‚¨æ¯å¼ å›¾åƒçš„è¯„ä¼°æŒ‡æ ‡
nrmse_list, mae_list, ms_ssim_list, ssim_list, psnr_list = [], [], [], [], []
nrmse_ipt_list, mae_ipt_list, ms_ssim_ipt_list, ssim_ipt_list, psnr_ipt_list = [], [], [], [], []

for i in range(n_images):
    image_diff_trajectory = generated_images[:, i]  # shape: (T, C, H, W)
    generated_high_res_image = image_diff_trajectory[-1]  # æœ€åä¸€å¸§
    target_high_res_image = test_target_images[i]
    input_low_res_image = test_input_images[i]

    # å°†å›¾åƒè½¬åˆ° CPU
    gen_img = generated_high_res_image.cpu()
    tgt_img = target_high_res_image.cpu()
    ipt_img = input_low_res_image.cpu()

    # diff = tgt_img - ipt_img
    # diff = tgt_img - gen_img
    # np.save(f'diff_gen{i}.npy',diff)

    # æŒ‡æ ‡è®¡ç®— -- gen
    mae = torch.mean(torch.abs(gen_img - tgt_img)).item()
    nrmse = torch.sqrt(torch.mean((gen_img - tgt_img) ** 2)) / (tgt_img.max() - tgt_img.min())
    nrmse = nrmse.item()

    mae_list.append(mae)
    nrmse_list.append(nrmse)

    ms_ssim_val = ms_ssim_metric(gen_img.unsqueeze(0), tgt_img.unsqueeze(0)).item()
    ssim_val    = ssim_metric(gen_img.unsqueeze(0), tgt_img.unsqueeze(0)).item()
    psnr_val    = psnr_metric(gen_img.unsqueeze(0), tgt_img.unsqueeze(0)).item()

    ms_ssim_list.append(ms_ssim_val)
    ssim_list.append(ssim_val)
    psnr_list.append(psnr_val)

    # æŒ‡æ ‡è®¡ç®— -- input
    mae_ipt = torch.mean(torch.abs(ipt_img - tgt_img)).item()
    nrmse_ipt = torch.sqrt(torch.mean((ipt_img - tgt_img) ** 2)) / (tgt_img.max() - tgt_img.min())
    nrmse_ipt = nrmse_ipt.item()

    mae_ipt_list.append(mae_ipt)
    nrmse_ipt_list.append(nrmse_ipt)

    ms_ssim_ipt_val = ms_ssim_metric(ipt_img.unsqueeze(0), tgt_img.unsqueeze(0)).item()
    ssim_ipt_val    = ssim_metric(ipt_img.unsqueeze(0), tgt_img.unsqueeze(0)).item()
    psnr_ipt_val    = psnr_metric(ipt_img.unsqueeze(0), tgt_img.unsqueeze(0)).item()

    ms_ssim_ipt_list.append(ms_ssim_ipt_val)
    ssim_ipt_list.append(ssim_ipt_val)
    psnr_ipt_list.append(psnr_ipt_val)

# è¾“å‡ºå¹³å‡æŒ‡æ ‡
print("\n=== Average Metrics on {} Test Images ===".format(n_images))
print("NRMSE:   {:.6f}".format(np.mean(nrmse_list)))
print("MAE:     {:.6f}".format(np.mean(mae_list)))
print("MS-SSIM: {:.6f}".format(np.mean(ms_ssim_list)))
print("SSIM:    {:.6f}".format(np.mean(ssim_list)))
print("PSNR:    {:.6f}".format(np.mean(psnr_list)))

print("\n=== Average Metrics on {} Input Images ===".format(n_images))
print("NRMSE:   {:.6f}".format(np.mean(nrmse_ipt_list)))
print("MAE:     {:.6f}".format(np.mean(mae_ipt_list)))
print("MS-SSIM: {:.6f}".format(np.mean(ms_ssim_ipt_list)))
print("SSIM:    {:.6f}".format(np.mean(ssim_ipt_list)))
print("PSNR:    {:.6f}".format(np.mean(psnr_ipt_list)))


# ==== ä½œå›¾ ====
palette = sns.color_palette("Dark2")
image_ids = list(range(1, n_images + 1))

fig, ax = plt.subplots(1, 3, figsize=(19, 5))

# 1. NRMSE & MAE
ax[0].plot(image_ids, mae_list, color=palette[0], marker='s', label="MAE")
ax[0].plot(image_ids, nrmse_list, color=palette[1], marker='o', label="NRMSE")
ax[0].plot(image_ids, mae_ipt_list, color=palette[3], marker='s', label="MAE_ipt")
ax[0].plot(image_ids, nrmse_ipt_list, color=palette[4], marker='o', label="NRMSE_ipt")
ax[0].set_xlabel("Image Index")
ax[0].set_ylabel("Value")
ax[0].set_title("NRMSE & MAE per Image")
ax[0].legend()
ax[0].grid(True)

# 2. MS-SSIM & SSIM
ax[1].plot(image_ids, ms_ssim_list, color=palette[3], marker='o', label="MS-SSIM")
ax[1].plot(image_ids, ssim_list, color=palette[4], marker='s', label="SSIM")
ax[1].plot(image_ids, ms_ssim_ipt_list, color=palette[5], marker='o', label="MS-SSIM_ipt")
ax[1].plot(image_ids, ssim_ipt_list, color=palette[6], marker='s', label="SSIM_ipt")
ax[1].set_xlabel("Image Index")
ax[1].set_ylabel("Value")
ax[1].set_title("MS-SSIM & SSIM per Image")
ax[1].legend()
ax[1].grid(True)

# 3. PSNR
ax[2].plot(image_ids, psnr_list, color=palette[5], marker='o', label="PSNR_ipt")
ax[2].plot(image_ids, psnr_ipt_list, color=palette[7], marker='o', label="PSNR_ipt")
ax[2].set_xlabel("Image Index")
ax[2].set_ylabel("Value")
ax[2].set_title("PSNR per Image")
ax[2].legend()
ax[2].grid(True)

plt.tight_layout()

savefig3_path = f'{save_dir_eval}/Eval_metrics_{model_weight_name}.png'
plt.savefig(savefig3_path)
plt.close()
logger.info(f"Evaluation plots saved at {savefig3_path}")
logger.success("========= 2-4-3 NRMSE, MAE, MS-SSIM, SSIM, PSNR è¯„ä¼°å®Œæˆ =========")


# from pathlib import Path
# import os
# import numpy as np
# import matplotlib.pyplot as plt
# import pandas as pd

# # -----------------------------
# # 1) ä¿å­˜å‰ 3 å¯¹å›¾ç‰‡ä¸º png + npy
# # -----------------------------
# base_dir = Path("/root/LHAI/images_1000")
# dir_input = base_dir / "input"
# dir_target = base_dir / "target"
# dir_generated = base_dir / "generated"
# for d in [dir_input, dir_target, dir_generated]:
#     d.mkdir(parents=True, exist_ok=True)

# def _to_2d_numpy(t):
#     """(C,H,W) or (1,H,W) -> (H,W) numpy, ä¸åšå½’ä¸€åŒ–"""
#     arr = t.detach().cpu().numpy()
#     return arr.squeeze()

# def _save_png(arr2d, path_png, cmap="viridis"):
#     """PNG å¯è§†åŒ–ï¼šæŒ‰ min-max å½’ä¸€åŒ–åˆ° [0,1]ï¼Œä¸æ”¹å˜ .npy çš„åŸå§‹æ•°å€¼"""
#     a = arr2d.astype(np.float64)
#     vmin, vmax = a.min(), a.max()
#     if vmax > vmin:
#         a = (a - vmin) / (vmax - vmin)
#     else:
#         a = np.zeros_like(a)
#     plt.imsave(path_png, a, cmap=cmap)

# # ç”Ÿæˆå›¾åƒï¼ˆå¦‚æœä½ åœ¨ä¸Šé¢å·²ç»ç®—è¿‡ generated_imagesï¼Œå°±å¤ç”¨ï¼‰
# # generated_images ç»´åº¦æ˜¯ (B, T, C, H, W)ï¼Œå–æœ€åä¸€å¸§ï¼š
# #   traj = generated_images[:, i] -> (T, C, H, W)
# #   traj[-1] -> (C, H, W)

# num_to_save = n_images
# for idx in range(num_to_save):
#     # å–ä¸‰è€… 2D æ•°ç»„
#     gen_img_2d = _to_2d_numpy(generated_images[:, idx][-1])   # (H,W)
#     tgt_img_2d = _to_2d_numpy(test_target_images[idx])
#     ipt_img_2d = _to_2d_numpy(test_input_images[idx])

#     # æ–‡ä»¶åï¼ˆ1 å¼€å§‹ç¼–å·ï¼‰
#     i1 = idx + 1
#     in_png  = dir_input     / f"input_{i1}.png"
#     in_npy  = dir_input     / f"input_{i1}.npy"
#     gt_png  = dir_target    / f"target_{i1}.png"
#     gt_npy  = dir_target    / f"target_{i1}.npy"
#     gen_png = dir_generated / f"generated_{i1}.png"
#     gen_npy = dir_generated / f"generated_{i1}.npy"

#     # å­˜ npyï¼ˆåŸå§‹æ•°å€¼ï¼‰
#     np.save(in_npy,  ipt_img_2d)
#     np.save(gt_npy,  tgt_img_2d)
#     np.save(gen_npy, gen_img_2d)

#     # å­˜ pngï¼ˆå¯è§†åŒ–ï¼‰
#     _save_png(ipt_img_2d, in_png)
#     _save_png(tgt_img_2d, gt_png)
#     _save_png(gen_img_2d, gen_png)

# print(f"âœ… Saved first {num_to_save} pairs to:\n  {dir_input}\n  {dir_target}\n  {dir_generated}")

# # ----------------------------------------
# # 2) ç”Ÿæˆ Excelï¼š/root/LHAI/images/eval.xlsx
# #    sheet1: input æŒ‡æ ‡ï¼›sheet2: generated æŒ‡æ ‡
# # ----------------------------------------
# # ç»„è£… DataFrameï¼ˆå›¾ç‰‡ç¼–å·ä» 1 å¼€å§‹ï¼‰
# img_ids = np.arange(1, n_images + 1)

# df_input = pd.DataFrame({
#     "id": img_ids,
#     "NRMSE":   np.asarray(nrmse_ipt_list, dtype=np.float64),
#     "MAE":     np.asarray(mae_ipt_list, dtype=np.float64),
#     "MS-SSIM": np.asarray(ms_ssim_ipt_list, dtype=np.float64),
#     "SSIM":    np.asarray(ssim_ipt_list, dtype=np.float64),
#     "PSNR":    np.asarray(psnr_ipt_list, dtype=np.float64),
# })

# df_generated = pd.DataFrame({
#     "id": img_ids,
#     "NRMSE":   np.asarray(nrmse_list, dtype=np.float64),
#     "MAE":     np.asarray(mae_list, dtype=np.float64),
#     "MS-SSIM": np.asarray(ms_ssim_list, dtype=np.float64),
#     "SSIM":    np.asarray(ssim_list, dtype=np.float64),
#     "PSNR":    np.asarray(psnr_list, dtype=np.float64),
# })

# excel_path = base_dir / "eval.xlsx"
# with pd.ExcelWriter(excel_path, engine="xlsxwriter") as writer:
#     df_input.to_excel(writer, sheet_name="input", index=False)
#     df_generated.to_excel(writer, sheet_name="generated", index=False)

# print(f"âœ… Excel saved: {excel_path}")

