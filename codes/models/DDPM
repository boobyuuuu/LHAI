import torch
import torch.nn as nn
from tqdm import tqdm


class DDPM:
    """Denoising Diffusion Probabilistic Model (DDPM)."""

    def __init__(
        self,
        noise_steps=1000,
        beta_start=1e-4,
        beta_end=0.02,
        img_size=64,
        device=None,
        position_encoding_fn=None,
        position_encoding_dim=None,
        conditional=True,
    ):
        self.noise_steps = noise_steps
        self.beta_start = beta_start
        self.beta_end = beta_end
        self.img_size = img_size
        self.device = device or torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.conditional = conditional

        # Noise schedule
        self.beta = torch.linspace(beta_start, beta_end, noise_steps, device=self.device)
        self.alpha = (1.0 - self.beta).to(self.device)
        self.alpha_bar = torch.cumprod(self.alpha, dim=0).to(self.device)

        # Positional encoding
        self.pos_enc_fn = position_encoding_fn
        self.pos_enc_dim = position_encoding_dim

    # -------------------
    # Forward diffusion (q)
    # -------------------
    def forward_diffusion(self, x0, t):
        """
        q(x_t | x_0)
        """
        sqrt_alpha_bar = torch.sqrt(self.alpha_bar[t])[:, None, None, None]
        sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bar[t])[:, None, None, None]
        noise = torch.randn_like(x0)
        x_t = sqrt_alpha_bar * x0 + sqrt_one_minus_alpha_bar * noise
        return x_t, noise

    # -------------------
    # Prepare batch for training
    # -------------------
    def sample_training_batch(self, input_img, target_img):
        """
        Prepare input for training step.
        input_img: condition image (low-res or degraded)
        target_img: ground truth clean image
        """
        b = target_img.shape[0]
        t = torch.randint(low=0, high=self.noise_steps, size=(b,), device=self.device)

        x_t, noise = self.forward_diffusion(target_img, t)

        # conditional: concat degraded + noisy
        if self.conditional:
            x_t = torch.cat((input_img.to(self.device), x_t), dim=1)

        # positional encoding
        if self.pos_enc_fn is not None:
            t_emb = self.pos_enc_fn(t.unsqueeze(1), self.pos_enc_dim).to(self.device)
        else:
            t_emb = t

        return x_t.to(self.device), t_emb, noise.to(self.device)

    # -------------------
    # Reverse diffusion (p)
    # -------------------
    @torch.no_grad()
    def reverse_diffusion(self, model, n_images, n_channels, input_image=None, save_time_steps=None):
        """
        p(x_{t-1} | x_t, input_image)
        """
        x = torch.randn((n_images, n_channels, self.img_size, self.img_size), device=self.device)
        alpha = self.alpha
        alpha_bar = self.alpha_bar

        denoised_images = []
        for i in tqdm(reversed(range(0, self.noise_steps)), desc="Sampling", total=self.noise_steps):
            t = torch.full((n_images,), i, dtype=torch.long, device=self.device)

            # timestep encoding
            if self.pos_enc_fn is not None:
                t_emb = self.pos_enc_fn(t.unsqueeze(1), self.pos_enc_dim).to(self.device)
            else:
                t_emb = t

            # concat conditional input
            xt_input = x
            if self.conditional and input_image is not None:
                xt_input = torch.cat((input_image.to(self.device), x), dim=1)

            predicted_noise = model(xt_input, t_emb)

            alpha_t = alpha[t][:, None, None, None]
            alpha_bar_t = alpha_bar[t][:, None, None, None]

            noise = torch.randn_like(x) if i > 0 else torch.zeros_like(x)

            x = (1 / torch.sqrt(alpha_t)) * (
                x - ((1 - alpha_t) / torch.sqrt(1 - alpha_bar_t)) * predicted_noise
            ) + torch.sqrt(1 - alpha_t) * noise

            if save_time_steps and i in save_time_steps:
                denoised_images.append(x)

        if save_time_steps:
            denoised_images = torch.stack(denoised_images).swapaxes(0, 1)
            return denoised_images
        return x
