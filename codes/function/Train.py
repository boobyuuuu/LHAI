# ---- 1-2 Libraries for Configuration and Modules ----
from codes.config.config_cnn import TrainConfig
from codes.function.Dataset import ImageDataset
import codes.function.Loss as lossfunction
from codes.function.Log import log
from codes.models.DIFFUSION import positional_encoding
from codes.models.DIFFUSION import prepare_data
# ---- 1-3 Libraries for pytorch and others ----
import torch
import torch.nn as nn
import torch.cuda
from torch.utils.data import DataLoader,random_split, ConcatDataset
import torch.nn.functional as F
import importlib
import matplotlib.pyplot as plt
import numpy as np
import time
from datetime import timedelta
import os
from typing import List, Optional
from torch.nn.utils import clip_grad_norm_

def format_model_params(params: dict, indent: int = 8) -> str:
    max_len = max(len(str(k)) for k in params)
    pad = " " * indent  # æ§åˆ¶ç¼©è¿›å®½åº¦
    return "\n".join(
        f"{pad}â€¢ {k:<{max_len}} : {v}"
        for k, v in params.items()
    )

def train_cnn(
    model,
    optimizer,
    scheduler,
    criterion,
    device,
    trainloader,
    testloader,
    num_epochs,
    logger,
    logpath,
    train_msg="",
    LOSS_PLOT=[],
    TESTLOSS_PLOT=[],
    EPOCH_PLOT=[],
    Best_model_save_path=""
):
    """
    å‡½æ•°ç‰¹è‰²ï¼šä½¿ç”¨scheduleråŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡ã€‚ä¼¼ä¹æ²¡æœ‰å…¶ä»–åœ¨trainå‡½æ•°è¿›è¡Œä¼˜åŒ–çš„æ–¹å¼ï¼Ÿ
    """
    with open(logpath, "w", encoding="utf-8"):
        pass
    log(logpath,train_msg)

    best_loss = float('inf')

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0.0
        current_lr = scheduler.get_last_lr()[0]

        for _, (img_LR, img_HR) in enumerate(trainloader):
            img_LR = img_LR.to(device)
            img_HR = img_HR.to(device)
            img_SR, _, _ = model(img_LR)
            loss = criterion(img_SR, img_HR)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_loss = total_loss / len(trainloader)

        # ===== éªŒè¯é˜¶æ®µ =====
        test_loss = 0.0
        model.eval()
        with torch.no_grad():
            for _, (img_LR, img_HR) in enumerate(testloader):
                img_LR = img_LR.to(device)
                img_HR = img_HR.to(device)
                img_SR, _, _ = model(img_LR)
                loss = criterion(img_SR, img_HR)
                test_loss += loss.item()
        test_avg_loss = test_loss / len(testloader)

        # ===== æ—¥å¿—è¾“å‡º =====
        logger.info(f"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4e}, Test Loss: {test_avg_loss:.4e}, LR: {current_lr:.4e}")
        log(logpath,f"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4e}, Test Loss: {test_avg_loss:.4e}, LR: {current_lr:.4e}")

        LOSS_PLOT.append(avg_loss)
        TESTLOSS_PLOT.append(test_avg_loss)
        EPOCH_PLOT.append(epoch)

        # ===== ä¿å­˜æœ€ä½³æ¨¡å‹ =====
        if test_avg_loss < best_loss:
            best_loss = test_avg_loss
            torch.save(model.state_dict(), Best_model_save_path)
            logger.success(f"ğŸ’¾ å‘ç°æ›´ä¼˜æ¨¡å‹ï¼ˆTest Loss={best_loss:.4e}ï¼‰ï¼Œå·²ä¿å­˜ï¼š{Best_model_save_path} (Epoch {epoch+1})")

        scheduler.step()

def train_DDPM(
    unet,                       # å™ªå£°é¢„æµ‹ç½‘ç»œï¼ˆå¦‚ AttentionUNet åŒ…è£…ï¼‰
    diffusion,                  # ä½ çš„ DDPM_Transformer / DDPM å®ä¾‹
    optimizer,
    scheduler,
    criterion,                  # ä¸€èˆ¬ç”¨ nn.MSELoss()ï¼Œæ¯”è¾ƒ predicted_noise vs true_noise
    device,
    trainloader,
    testloader,
    num_epochs: int,
    logger,
    logpath: str,
    train_msg: str = "",
    LOSS_PLOT: Optional[List[float]] = None,
    TESTLOSS_PLOT: Optional[List[float]] = None,
    EPOCH_PLOT: Optional[List[int]] = None,
    Best_model_save_path: str = "",
    grad_clip: Optional[float] = None,  # e.g., 1.0ï¼›None è¡¨ç¤ºä¸è£å‰ª
    eval_sample_every: Optional[int] = None,  # e.g., 10ï¼›None è¡¨ç¤ºä¸åšé‡‡æ ·è¯„ä¼°
    save_time_steps: Optional[List[int]] = None,  # éœ€è¦å¯è§†åŒ–ä¸­é—´è¿‡ç¨‹æ—¶ä¼ å…¥
):
    """
    è®­ç»ƒ DDPMï¼ˆå™ªå£°é¢„æµ‹ï¼‰ç‰ˆçš„è¶…åˆ†è¾¨ï¼š
    - è®­ç»ƒç›®æ ‡ï¼šmin E[ || eps_pred - eps_true ||^2 ]
    - éªŒè¯åŒè®­ç»ƒï¼ˆä¸èµ°å®Œæ•´åå‘é‡‡æ ·ï¼Œé€Ÿåº¦å¿«ä¸”ç¨³å®šï¼‰
    - å¯é€‰ï¼šæ¯ N ä¸ª epoch è¿›è¡Œä¸€æ¬¡å°æ ·æœ¬åæ¨é‡‡æ ·ï¼ˆè€—æ—¶ï¼Œé»˜è®¤å…³é—­ï¼‰

    è¯´æ˜ï¼š
    - diffusion.sample_training_batch ä¼šå®Œæˆï¼š
        1) é‡‡æ · t
        2) å‰å‘åŠ å™ªå¾—åˆ° x_t ä¸çœŸå®å™ªå£° noise
        3) è‹¥ conditional=Trueï¼Œåˆ™å°† input_img ä¸ x_t åœ¨é€šé“ç»´æ‹¼æ¥
        4) è¿”å› (x_t_concat, t_emb, noise)
    """

    # --- åˆå§‹åŒ–ç»˜å›¾ç¼“å­˜ ---
    LOSS_PLOT = [] if LOSS_PLOT is None else LOSS_PLOT
    TESTLOSS_PLOT = [] if TESTLOSS_PLOT is None else TESTLOSS_PLOT
    EPOCH_PLOT = [] if EPOCH_PLOT is None else EPOCH_PLOT

    # --- é‡ç½®æ—¥å¿—æ–‡ä»¶ ---
    with open(logpath, "w", encoding="utf-8"):
        pass
    log(logpath, train_msg)

    best_loss = float('inf')

    for epoch in range(num_epochs):
        unet.train()
        total_loss = 0.0
        current_lr = scheduler.get_last_lr()[0]

        # ====== è®­ç»ƒ ======
        for _, (img_LR, img_HR) in enumerate(trainloader):
            img_LR = img_LR.to(device)
            img_HR = img_HR.to(device)

            # å‡†å¤‡å¸¦å™ªè¾“å…¥ä¸æ—¶é—´æ­¥åµŒå…¥
            x_t, t_emb, noise_true = diffusion.sample_training_batch(
                input_img=img_LR, target_img=img_HR
            )

            # é¢„æµ‹å™ªå£°
            noise_pred = unet(x_t, t_emb)

            loss = criterion(noise_pred, noise_true)

            optimizer.zero_grad(set_to_none=True)
            loss.backward()

            if grad_clip is not None and grad_clip > 0:
                clip_grad_norm_(unet.parameters(), max_norm=grad_clip)

            optimizer.step()
            total_loss += loss.item()

        avg_loss = total_loss / max(1, len(trainloader))

        # ====== éªŒè¯ ======
        test_loss = 0.0
        unet.eval()
        with torch.no_grad():
            for _, (img_LR, img_HR) in enumerate(testloader):
                img_LR = img_LR.to(device)
                img_HR = img_HR.to(device)

                x_t, t_emb, noise_true = diffusion.sample_training_batch(
                    input_img=img_LR, target_img=img_HR
                )
                noise_pred = unet(x_t, t_emb)
                loss = criterion(noise_pred, noise_true)
                test_loss += loss.item()

        test_avg_loss = test_loss / max(1, len(testloader))

        # ====== æ—¥å¿— ======
        logger.info(
            f"[DDPM] Epoch [{epoch+1}/{num_epochs}] "
            f"Train: {avg_loss:.4e} | Val: {test_avg_loss:.4e} | LR: {current_lr:.4e}"
        )
        log(
            logpath,
            f"[DDPM] Epoch [{epoch+1}/{num_epochs}] "
            f"Train: {avg_loss:.4e} | Val: {test_avg_loss:.4e} | LR: {current_lr:.4e}"
        )

        LOSS_PLOT.append(avg_loss)
        TESTLOSS_PLOT.append(test_avg_loss)
        EPOCH_PLOT.append(epoch)

        # ====== ä¿å­˜æœ€ä¼˜æƒé‡ï¼ˆæŒ‰éªŒè¯é›†å™ªå£°é¢„æµ‹æŸå¤±ï¼‰ ======
        if test_avg_loss < best_loss and Best_model_save_path:
            best_loss = test_avg_loss
            torch.save(unet.state_dict(), Best_model_save_path)
            logger.success(
                f"ğŸ’¾ å‘ç°æ›´ä¼˜æ¨¡å‹ï¼ˆVal NoiseLoss={best_loss:.4e}ï¼‰ï¼Œå·²ä¿å­˜ï¼š{Best_model_save_path} (Epoch {epoch+1})"
            )

        # ====== å¯é€‰ï¼šå°æ ·æœ¬åå‘é‡‡æ ·ï¼ˆæ…¢ï¼Œé»˜è®¤å…³é—­ï¼‰ ======
        do_sample = (eval_sample_every is not None) and ((epoch + 1) % eval_sample_every == 0)
        if do_sample:
            try:
                # å–ä¸€ä¸ªå° batch åšç¤ºä¾‹ï¼ˆæ¯”å¦‚å‰ 4 å¼ ï¼‰
                img_LR, img_HR = next(iter(testloader))
                img_LR = img_LR.to(device)
                img_HR = img_HR.to(device)
                n = min(4, img_LR.size(0))
                # åå‘æ‰©æ•£ï¼ˆæ¡ä»¶é‡‡æ ·ï¼‰
                samples = diffusion.reverse_diffusion(
                    model=unet,
                    n_images=n,
                    n_channels=img_HR.size(1),
                    input_image=img_LR[:n] if getattr(diffusion, "conditional", True) else None,
                    save_time_steps=save_time_steps
                )
                # è¿™é‡Œä¸å¼ºåˆ¶è®¡ç®— PSNR/SSIMï¼ˆå› æ•°æ®å½’ä¸€åŒ–ä¸åŒï¼‰ï¼Œå¦‚éœ€å¯åœ¨æ­¤å¤„æ·»åŠ 
                logger.info(f"[DDPM] Epoch {epoch+1}: é‡‡æ ·å®Œæˆï¼ˆç¤ºä¾‹ n={n}ï¼‰")
            except Exception as e:
                logger.warning(f"[DDPM] é‡‡æ ·å¤±è´¥ï¼ˆè·³è¿‡ï¼‰ï¼š{e}")

        scheduler.step()


def train_diffusion(
    unet,
    optimizer,
    scheduler,
    criterion,
    device,
    trainloader,
    testloader,
    diffusion,
    noise_steps,
    position_encoding_dim,
    positional_encoding,
    num_epochs,
    logger,
    logpath,
    train_msg,
    EVALUATE_METRICS=False,
    mae_metric=None,
    ms_ssim_metric=None,
    ssim_metric=None,
    psnr_metric=None,
    train_loss=None,
    mae_results=None,
    ms_ssim_results=None,
    ssim_results=None,
    psnr_results=None,
    nrmse_results=None,
):
    """
    è®­ç»ƒå‡½æ•°ï¼ŒåŒ…å«è®­ç»ƒã€æµ‹è¯•å’Œè¯„ä¼°æŒ‡æ ‡è®¡ç®—ï¼Œæ”¯æŒå­¦ä¹ ç‡è°ƒåº¦ã€‚

    å‚æ•°:
        unet: å¾…è®­ç»ƒçš„æ¨¡å‹
        optimizer: ä¼˜åŒ–å™¨
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        criterion: æŸå¤±å‡½æ•°
        device: è®­ç»ƒè®¾å¤‡
        trainloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        testloader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        diffusion: diffusionæ¨¡å‹å¯¹è±¡ï¼Œå«reverse_diffusionæ–¹æ³•
        noise_steps: å™ªå£°æ­¥æ•°å‚æ•°
        position_encoding_dim: ä½ç½®ç¼–ç ç»´åº¦
        positional_encoding: ä½ç½®ç¼–ç å‡½æ•°
        num_epochs: è®­ç»ƒè½®æ•°
        logger: æ—¥å¿—è®°å½•å™¨
        logpath: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        EVALUATE_METRICS: æ˜¯å¦è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼Œbool
        mae_metric, ms_ssim_metric, ssim_metric, psnr_metric: è¯„ä¼°æŒ‡æ ‡å‡½æ•°ï¼ˆå¯é€‰ï¼‰
        train_loss, mae_results, ms_ssim_results, ssim_results, psnr_results, nrmse_results: è®°å½•åˆ—è¡¨ï¼ˆå¤–éƒ¨ä¼ å…¥ä»¥ä¾¿ä¿å­˜å†å²ï¼‰
    """
    with open(logpath, "w", encoding="utf-8"):
        pass
    log(logpath,train_msg)
    for epoch in range(num_epochs):
        start_time = time.time()
        num_batches = len(trainloader)

        logger.info(f"Epoch {epoch + 1}/{num_epochs}" + "\n" + "_" * 10)
        log(logpath,f"Epoch {epoch + 1}/{num_epochs}" + "\n" + "_" * 10)

        unet.train()
        running_loss = 0.0

        current_lr = scheduler.get_last_lr()[0]

        for batch_idx, \
            (input_images, target_images) in enumerate(trainloader, start=0):
            x_t, t, noise = prepare_data(input_images, target_images, diffusion, noise_steps, device, position_encoding_dim)

            outputs = unet(x=x_t, t=t)
            optimizer.zero_grad()
            loss = criterion(outputs, noise)
            loss.backward()
            optimizer.step()

            if batch_idx % 200 == 0:
                print(f"Batch {batch_idx + 1}/{num_batches}: " \
                    + f"Train loss: {loss.item():.4f}")
            running_loss += loss.item()

            train_loss.append(running_loss / num_batches)
            end_time = time.time()

        logger.info("-" * 10 + "\n" + f"Epoch {epoch + 1}/{num_epochs} : "
                    + f"Train loss: {train_loss[-1]:.4f}, "
                    + f"Time taken: {timedelta(seconds=end_time - start_time)}")
        log(logpath,"-" * 10 + "\n" + f"Epoch {epoch + 1}/{num_epochs} : "
                    + f"Train loss: {train_loss[-1]:.4f}, "
                    + f"Time taken: {timedelta(seconds=end_time - start_time)}")

        # # è¯„ä¼°é˜¶æ®µ
        # unet.eval()

        # running_mae = 0.0
        # running_ms_ssim = 0.0
        # running_ssim = 0.0
        # running_psnr = 0.0
        # running_nrmse = 0.0

        # n_images = 4

        # for batch_idx, (test_input_images, \
        #             test_target_images) in enumerate(testloader):

        #     num_batches = len(testloader)
        #     test_input_images = test_input_images.to(device)
        #     test_target_images = test_target_images.to(device)

        #     generated_images = diffusion.reverse_diffusion(
        #         model=unet,
        #         n_images=test_input_images.shape[0] if EVALUATE_METRICS else n_images,
        #         n_channels=1,
        #         position_encoding_dim=position_encoding_dim,
        #         position_encoding_function=positional_encoding,
        #         input_image=test_input_images if EVALUATE_METRICS else \
        #             test_input_images[:n_images],
        #         save_time_steps=[0],
        #     )

        #     if EVALUATE_METRICS:
        #         generated_images_reshaped = generated_images.swapaxes(0, 1)[0]

        #         # Calculating the metrics for each batch
        #         batch_mae = mae_metric(generated_images_reshaped, test_target_images)
        #         batch_ms_ssim = ms_ssim_metric(generated_images_reshaped, test_target_images)
        #         batch_ssim = ssim_metric(generated_images_reshaped, test_target_images)
        #         batch_psnr = psnr_metric(generated_images_reshaped, test_target_images)
        #         batch_nrmse = torch.sqrt(
        #             torch.mean((generated_images_reshaped - test_target_images) ** 2)
        #         ) / (test_target_images.max() - test_target_images.min())

        #         # Accumulating the metrics
        #         running_mae += batch_mae.item()
        #         running_ms_ssim += batch_ms_ssim.item()
        #         running_ssim += batch_ssim.item()
        #         running_psnr += batch_psnr.item()
        #         running_nrmse += batch_nrmse.item()

        #     else:
        #         break

        # if EVALUATE_METRICS:
        #     # Storing the mean metric values per epoch to the empty lists
        #     mae_results.append(running_mae / num_batches)
        #     ms_ssim_results.append(running_ms_ssim / num_batches)
        #     ssim_results.append(running_ssim / num_batches)
        #     psnr_results.append(running_psnr / num_batches)
        #     nrmse_results.append(running_nrmse / num_batches)

        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
