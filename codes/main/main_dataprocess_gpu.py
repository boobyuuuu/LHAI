# main_dataprocess_gpu.py

# ---- 1-1 Libraries for Path and Logging ----
from pathlib import Path
import typer
from loguru import logger
from tqdm import tqdm
import sys
ADDR_ROOT = Path(__file__).resolve().parents[2]
logger.success(f"ADDR_ROOT path is: {ADDR_ROOT}")
ADDR_CODE = Path(__file__).resolve().parents[1]
sys.path.append(str(ADDR_ROOT))
logger.success(f"ADDR_CODE path is: {ADDR_CODE}")

# ---- 1-2 Libraries for dataprocess ----
from codes.function.dataprocess_gpu import ImageDataset
import numpy as np
import argparse
import torch

def main():
    parser = argparse.ArgumentParser(description="ğŸ”§ å›¾åƒæ•°æ®é¢„å¤„ç†ï¼ˆGPUåŠ é€Ÿï¼‰")
    parser.add_argument('--input_path', type=str, required=True, help="åŸå§‹æ•°æ®è·¯å¾„ï¼Œä¾‹å¦‚ data/xxx.npy")
    parser.add_argument('--output_path', type=str, required=True, help="å¤„ç†åæ•°æ®ä¿å­˜è·¯å¾„ï¼Œä¾‹å¦‚ data/processed_xxx.npy")
    parser.add_argument('--num_to_learn', type=int, default=10000, help="è¯»å–æ ·æœ¬æ•°é‡")
    parser.add_argument('--data_range', type=float, default=1.0, choices=[1.0, 2.0], help="å½’ä¸€åŒ–èŒƒå›´ï¼š1.0 æˆ– 2.0")
    parser.add_argument('--inverse', action='store_true', help="æ˜¯å¦ä»æ•°æ®å°¾éƒ¨åŠ è½½æ ·æœ¬")

    # é¢„å¤„ç†é€‰é¡¹
    parser.add_argument('--remove_duplicates', action='store_true', help="æ˜¯å¦å»é™¤é‡å¤å›¾åƒ")
    parser.add_argument('--augment', action='store_true', help="æ˜¯å¦è¿›è¡Œå›¾åƒæ‰©å……")
    parser.add_argument('--enhance', action='store_true', help="æ˜¯å¦è¿›è¡Œå¯¹æ¯”åº¦å¢å¼ºï¼ˆGammaï¼‰")
    parser.add_argument('--remove_low_info', action='store_true', help="æ˜¯å¦ç§»é™¤ä¿¡æ¯é‡ä½çš„å›¾åƒ")

    # è®¾å¤‡æ§åˆ¶
    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu', choices=['cuda', 'cpu'],
                        help="è¿è¡Œè®¾å¤‡ï¼šcuda æˆ– cpu")

    args = parser.parse_args()

    print(f"\nğŸš€ æ­£åœ¨ä½¿ç”¨è®¾å¤‡ï¼š{args.device}")
    print("ğŸ“¦ æ­£åœ¨åŠ è½½å¹¶å¤„ç†æ•°æ®...")

    dataset = ImageDataset(
        num_to_learn=args.num_to_learn,
        path_data=args.input_path,
        inverse=args.inverse,
        data_range=args.data_range,
        remove_duplicates=args.remove_duplicates,
        augment=args.augment,
        enhance=args.enhance,
        remove_low_info=args.remove_low_info,
        device=args.device
    )

    print(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œå…± {len(dataset)} ä¸ªæ ·æœ¬")

    # âœ… ä¿å­˜ä¸º shape=(N, 2, H, W)ï¼Œdtype=float32 çš„æ ‡å‡†å¼ é‡æ ¼å¼
    saved_data = []
    for blurry_tensor, original_tensor in dataset:
        sample = torch.stack([
            original_tensor.squeeze(0),  # [H, W]
            blurry_tensor.squeeze(0)     # [H, W]
        ], dim=0)  # shape: [2, H, W]
        saved_data.append(sample)
    
    saved_data_np = torch.stack(saved_data).numpy().astype(np.float32)  # [N, 2, H, W]
    
    output_path = Path(args.output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    np.save(output_path, saved_data_np)


    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_path.resolve()}\n")

if __name__ == '__main__':
    main()
