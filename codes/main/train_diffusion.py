# æ‰€æœ‰DIFFUSIONæ–¹æ¡ˆæ¨¡å‹é€šç”¨è®­ç»ƒæ¡†æ¶

# ---- 01 Improt Libraries ----
# ---- 1-1 Libraries for Path and Logging ----
from pathlib import Path
import typer
from loguru import logger
from tqdm import tqdm
import sys
ADDR_ROOT = Path(__file__).resolve().parents[2]
logger.success(f"ADDR_ROOT path is: {ADDR_ROOT}")
ADDR_CODE = Path(__file__).resolve().parents[1]
sys.path.append(str(ADDR_ROOT))
logger.success(f"ADDR_CODE path is: {ADDR_CODE}")
# ---- 1-2 Libraries for Configuration and Modules ----
from codes.config.config_diffusion import TrainConfig
from codes.function.Dataset import ImageDataset
import codes.function.Loss as lossfunction
from codes.function.Log import log
import codes.function.Train as Train
from codes.models.DIFFUSION import EnhancedUNetWrapper
from codes.models.DIFFUSION import Diffusion
from codes.models.DIFFUSION import positional_encoding
from codes.models.DIFFUSION import prepare_data
# ---- 1-3 Libraries for pytorch and others ----
import torch
import torch.nn as nn
import torch.cuda
from torch.utils.data import DataLoader,random_split, ConcatDataset
import torch.nn.functional as F
import importlib
import matplotlib.pyplot as plt
import numpy as np
import deeplay as dl
import time
from datetime import timedelta
from torchmetrics.image import MultiScaleStructuralSimilarityIndexMeasure as MS_SSIM
from torchmetrics.image import StructuralSimilarityIndexMeasure as SSIM
from torchmetrics.image import PeakSignalNoiseRatio as PSNR
from torchmetrics.regression import MeanAbsoluteError as MAE
import seaborn as sns

# ---- 02 Define the main function ----
train_cfg = TrainConfig()
app = typer.Typer()
@app.command()
def main(
    exp_name: str = train_cfg.exp_name,                  # para01ï¼šå®éªŒåç§° default: "EXP01"
    data_dir: Path = train_cfg.data_dir,                 # para05ï¼šæ•°æ®ç›®å½• default: ADDR_ROOT / "data" / "Train"
    data_name: str = train_cfg.data_name,                # para06ï¼šæ•°æ®æ–‡ä»¶å default: "xingwei_10000_64_train_v1.npy"
    model_dir: Path = train_cfg.model_dir,               # para03ï¼šæ¨¡å‹ç›®å½• default: ADDR_ROOT / "codes" / "models"
    model_name: str = train_cfg.model_name,              # para02ï¼šæ¨¡å‹åç§° default: "DIFFUSION"
    seed: int = train_cfg.seed,                          # para08ï¼šéšæœºç§å­ default: 0
    frac: float = train_cfg.frac,                        # para09ï¼šè®­ç»ƒé›†æ¯”ä¾‹ default: 0.8
    epochs: int = train_cfg.epochs,                      # para10ï¼šè®­ç»ƒè½®æ•° default: 400
    batch_size: int = train_cfg.batch_size,              # para11ï¼šæ‰¹æ¬¡å¤§å° default: 32
    lr_max: float = train_cfg.lr_max,                    # para12ï¼šæœ€å¤§å­¦ä¹ ç‡ default: 5e-4
    lr_min: float = train_cfg.lr_min,                    # para13ï¼šæœ€å°å­¦ä¹ ç‡ default: 5e-6
    datarange: float = train_cfg.datarange,              # para14ï¼šæ•°æ®èŒƒå›´ default: 1.0
    position_encoding_dim: int = train_cfg.position_encoding_dim,   # para15ï¼šä½ç½®ç¼–ç ç»´åº¦ default: 256
    noise_steps: int = train_cfg.noise_steps,            # para16ï¼šå™ªå£°æ­¥æ•° default: 2000
    EVALUATE_METRICS: bool = train_cfg.EVALUATE_METRICS, # para17ï¼šæ˜¯å¦è¯„ä¼°æŒ‡æ ‡ default: False
    log_dir: Path = train_cfg.log_dir,                   # para18ï¼šæ—¥å¿—æ–‡ä»¶å¤¹ default: ADDR_ROOT / "logs"
):
    #ã€é‡è¦ã€‘æ ¹æ®å‘½ä»¤è¡Œè¾“å…¥é‡æ–°å®šä¹‰å‚æ•°
    data_path = data_dir / data_name
    model_path = model_dir / f"{model_name}.py"
    logpath = log_dir / f"trainlog_{model_name}"
    # ---- 2-1 Load the parameter ----
    logger.info("========== å½“å‰è®­ç»ƒå‚æ•° ==========")
    for idx, (key, value) in enumerate(locals().items(), start=1):
        logger.info(f"{idx:02d}. {key:<20}: {value}")
    torch.manual_seed(seed)
    # spec = importlib.util.spec_from_file_location("module.name", model_path)
    # module = importlib.util.module_from_spec(spec)
    # sys.modules["module.name"] = module
    # spec.loader.exec_module(module)
    # MODEL = getattr(module, model_name)
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    data_sim = data_name.split("_")[0]
    model_save_name = f"{model_name}_{exp_name}_{epochs}epo_{batch_size}bth_{data_sim}"
    logger.success("âœ… å‚æ•°åŠ è½½å®Œæˆï¼ˆStep 2-1ï¼‰")
    
    # ---- 2-2 Load data ----
    filetmp = np.load(data_path, allow_pickle=True)
    filelen = filetmp.shape[0]
    del filetmp
    num_to_learn = int(filelen)

    dataset = ImageDataset(num_to_learn, data_path, inverse=False,data_range=datarange)
    trainset, testset = random_split(
        dataset,
        lengths=[int(frac * len(dataset)), len(dataset) - int(frac * len(dataset))],
        generator=torch.Generator().manual_seed(0)
    )

    trainloader = DataLoader(trainset, shuffle=True, batch_size=batch_size)
    testloader = DataLoader(testset, shuffle=True, batch_size=batch_size)

    for batch_idx, (blurry_img, original_img) in enumerate(trainloader):
        if batch_idx == 0:
            blurry_img_shape = blurry_img.shape  # ç¤ºä¾‹ï¼š(32, 1, 64, 64)
            original_img_shape = original_img.shape
            blurry_img_numpy = blurry_img[1].squeeze().detach().cpu().numpy()
            blurry_img_min = blurry_img_numpy.min()
            blurry_img_max = blurry_img_numpy.max()
            blurry_img_sample = blurry_img_numpy
            break

    logger.info(f"""
    ====================== ğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ ======================
    æ ·æœ¬æ¥æºï¼šç¬¬ä¸€ä¸ªè®­ç»ƒ mini-batchï¼ˆBatch 1ï¼‰

    - ğŸ–¼ï¸ æ¨¡ç³Šå›¾åƒå¼ é‡å°ºå¯¸     : {blurry_img_shape}ï¼ˆæ ¼å¼ï¼š[æ‰¹æ¬¡, é€šé“æ•°, é«˜åº¦, å®½åº¦]ï¼‰
    - ğŸ–¼ï¸ åŸå§‹å›¾åƒå¼ é‡å°ºå¯¸     : {original_img_shape}ï¼ˆæ ¼å¼ï¼š[æ‰¹æ¬¡, é€šé“æ•°, é«˜åº¦, å®½åº¦]ï¼‰
    - ğŸ”¢ æ¨¡ç³Šå›¾åƒåƒç´ å–å€¼èŒƒå›´ : æœ€å°å€¼ = {blurry_img_min:.6f}, æœ€å¤§å€¼ = {blurry_img_max:.6f}
    - ğŸ§ª æ¨¡ç³Šå›¾åƒæ ·æœ¬ï¼ˆç´¢å¼• 1ï¼‰äºŒç»´æ•°æ®å¦‚ä¸‹ï¼ˆæˆªå–ï¼‰ï¼š
    {np.array2string(blurry_img_sample, precision=4, suppress_small=True, threshold=64)}
    ===============================================================
    """)

    logger.success("âœ… æ•°æ®åŠ è½½å®Œæˆï¼ˆStep 2-2ï¼‰")

    # ---- 2-3 Initialize the model, loss function and optimizer ----
    # æ¨¡å‹
    unet = dl.AttentionUNet(
        in_channels=2,
        channels=[32, 64, 128],
        base_channels=[256, 256],
        channel_attention=[False, False, False],
        out_channels=1,
        position_embedding_dim=position_encoding_dim,
    )
    unet.build()
    unet.to(device)
    diffusion = Diffusion(
        noise_steps=noise_steps,
        img_size=64,
        beta_start=1e-6,
        beta_end=0.01,
    )
    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(unet.parameters(), lr=lr_max)
    lr_lambda = lambda epoch: lr_min / lr_max + 0.5 * (1 - lr_min / lr_max) * (1 + np.cos(np.pi * epoch / epochs))
    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
    # æŸå¤±å‡½æ•°
    criterion = lossfunction.msejsloss

    logger.success("âœ… æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨åŠ è½½å®Œæˆï¼ˆStep 2-3ï¼‰")

    # ---- 2-4 Start Training ----
    train = Train.train_diffusion  # ç¡®è®¤train_diffusionå‡½æ•°ç­¾åä¸ä¹‹å‰å®šä¹‰çš„trainä¸€è‡´

    ms_ssim_metric = MS_SSIM(
        data_range=datarange, kernel_size=7, betas=(0.0448, 0.2856, 0.3001)
    ).to(device)
    ssim_metric = SSIM(data_range=datarange).to(device)
    psnr_metric = PSNR(data_range=datarange).to(device)
    mae_metric = MAE().to(device)

    train_loss = []
    mae_results = []
    ms_ssim_results = []
    ssim_results = []
    psnr_results = []
    nrmse_results = []

    torch.set_printoptions(precision=10)
    gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No CUDA device"
    optimizer_name = optimizer.__class__.__name__                      # ä¼˜åŒ–å™¨ç±»åï¼Œä¾‹å¦‚ AdamW
    loss_name = criterion.__name__                                  # æŸå¤±å‡½æ•°åç§°ï¼Œä¾‹å¦‚ msejsloss

    train_msg = f"""
    ====================== ğŸš€ å¼€å§‹è®­ç»ƒ ======================
    ğŸ”§ é…ç½®ä¿¡æ¯æ€»è§ˆï¼š
    ğŸ“¦ å®éªŒåç§°             : {exp_name}
    ğŸ§  æ¨¡å‹åç§°             : {model_name}
    ğŸ“ æ¨¡å‹è„šæœ¬è·¯å¾„         : {model_path}
    ğŸ“‚ æ•°æ®æ–‡ä»¶è·¯å¾„         : {data_path}
    ğŸ“Š æ•°æ®é›†åˆ‡åˆ†æ¯”ä¾‹       : è®­ç»ƒé›† {frac*100:.1f}% / æµ‹è¯•é›† {100-frac*100:.1f}%
    ğŸ“ˆ æ ·æœ¬æ€»æ•°             : {filelen}
    ğŸ” æ€»è®­ç»ƒè½®æ•° (Epochs)  : {epochs}
    ğŸ“¦ æ‰¹æ¬¡å¤§å° (BatchSize)  : {batch_size}
    ğŸŒ± éšæœºç§å­ (Seed)      : {seed}
    ğŸ”¢ æ•°æ®å½’ä¸€åŒ–èŒƒå›´       : {datarange}
    ğŸ§© ä½ç½®ç¼–ç ç»´åº¦         : {position_encoding_dim}
    ğŸ² å™ªå£°æ­¥æ•°             : {noise_steps}
    ğŸ” æ˜¯å¦è¯„ä¼°æŒ‡æ ‡         : {EVALUATE_METRICS}
    ğŸ“‰ å­¦ä¹ ç‡ç­–ç•¥ (Cosine)  : æœ€å° = {lr_min:.1e}, æœ€å¤§ = {lr_max:.1e}
    ğŸ§ª æŸå¤±å‡½æ•° (Loss)      : {loss_name}
    ğŸ› ï¸ ä¼˜åŒ–å™¨ (Optimizer)  : {optimizer_name}
    ğŸ’» ä½¿ç”¨è®¾å¤‡ (Device)    : {device} ({gpu_name})
    ==============================================================
    """

    logger.info(train_msg)

    train(
        unet=unet,
        optimizer=optimizer,
        scheduler=scheduler,
        criterion=criterion,
        device=device,
        trainloader=trainloader,
        testloader=testloader,
        diffusion=diffusion,
        noise_steps=noise_steps,
        position_encoding_dim=position_encoding_dim,
        positional_encoding=positional_encoding,
        num_epochs=epochs,
        logger=logger,
        logpath=logpath,
        train_msg=train_msg,
        EVALUATE_METRICS=EVALUATE_METRICS,
        mae_metric=mae_metric,
        ms_ssim_metric=ms_ssim_metric,
        ssim_metric=ssim_metric,
        psnr_metric=psnr_metric,
        train_loss=train_loss,
        mae_results=mae_results,
        ms_ssim_results=ms_ssim_results,
        ssim_results=ssim_results,
        psnr_results=psnr_results,
        nrmse_results=nrmse_results,
    )

    logger.success("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼ˆStep 2-4ï¼‰")

    # ---- 2-5 Save the model and plot the loss ----
    savepath = ADDR_ROOT / "saves"
    loss_plot_path = savepath / "TRAIN" / f"{model_save_name}.png"
    loss_data_path = savepath / "TRAIN" / f"{model_save_name}.npy"
    model_save_folder = savepath / "MODEL"
    
    torch.save(unet.state_dict(), f'{model_save_folder}/unetconfig_{model_save_name}.pth')
    diffusion_config = {
        'noise_steps': diffusion.noise_steps,
        'beta_start': diffusion.beta_start,
        'beta_end': diffusion.beta_end,
        'img_size': diffusion.img_size,
    }
    torch.save(diffusion_config, f'{model_save_folder}/diffusionconfig_{model_save_name}.pth')
    
    # è®­ç»ƒè¿‡ç¨‹å›¾
    plt.figure()
    plt.plot(train_loss, "g-o", label="Training loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend()
    # plt.show()
    plt.savefig(loss_plot_path, dpi=300)

    palette = sns.color_palette("Dark2")
    fig, ax = plt.subplots(1, 3, figsize=(19,5))
    ax[0].plot(mae_results, color=palette[0], marker="o", label="MAE")
    ax[0].plot(nrmse_results, color=palette[1], marker="o", label="NRMSE")
    ax[0].set_xlabel("Epochs")
    ax[0].set_ylabel("MAE / NRMSE")
    ax[0].legend()

    ax[1].plot(ms_ssim_results, color=palette[3], marker="o", label="MS-SSIM")
    ax[1].plot(ssim_results, color=palette[4], marker="o", label="SSIM")
    ax[1].set_xlabel("Epochs")
    ax[1].set_ylabel("MS-SSIM / SSIM")
    ax[1].legend()

    ax[2].plot(psnr_results, color=palette[5], marker="o", label="PSNR")
    ax[2].set_xlabel("Epochs")
    ax[2].set_ylabel("PSNR")
    ax[2].legend()
    # plt.show()
    plt.tight_layout()
    plt.savefig(loss_plot_path, dpi=300)


    logger.success(f"Loss plot saved at {loss_plot_path}")
    logger.success(f"Loss data saved at {loss_data_path}")
    logger.success(f"Model saved at {model_save_folder}")
    logger.success("âœ… æ¨¡å‹ä¿å­˜å®Œæˆï¼ˆStep 2-5ï¼‰")
    # -----------------------------------------
if __name__ == "__main__":
    app()
